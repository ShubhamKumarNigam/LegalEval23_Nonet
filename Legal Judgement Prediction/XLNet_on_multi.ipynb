{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cs1Sb5vDyoLZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import textwrap\n",
    "import tqdm as tqdm\n",
    "import progressbar\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yqpk39qSy9bi"
   },
   "outputs": [],
   "source": [
    "df_multi = pd.read_csv(path to multi dataset) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_train_set = df_multi.query(\" split=='train' \")\n",
    "ori_val_set = df_multi.query(\" split=='dev' \")\n",
    "\n",
    "print(\"---------- Original ILDC_multi ----------\")\n",
    "print(\"Train :\\t\", len(ori_train_set))\n",
    "print(\"Val :\\t\", len(ori_val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df_multi.query(\" split=='train' \")\n",
    "test_set = df_multi.query(\" split=='test' \")\n",
    "val_set = df_multi.query(\" split=='dev' \")\n",
    "\n",
    "print(\"---------- Provided ILDC_multi ----------\")\n",
    "print(\"Train :\\t\", len(train_set))\n",
    "print(\"Val :\\t\", len(val_set))\n",
    "print(\"Test :\\t\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_multi\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df.query(\" split=='train' \")\n",
    "test_set = df.query(\" split=='test' \")\n",
    "validation_set = df.query(\" split=='dev' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set), len(validation_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 0\n",
    "c2 = 0\n",
    "for i in (validation_set['label'].values):\n",
    "    if i == 0:\n",
    "        c1 += 1\n",
    "    else:\n",
    "        c2 += 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84c1xdZMB176"
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'InLegalBERT': (BertForSequenceClassification, AutoTokenizer, AutoConfig),\n",
    "    'InCaseLawBERT': (BertForSequenceClassification, AutoTokenizer, AutoConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)}\n",
    "\n",
    "model_type = 'xlnet' ###--> CHANGE WHAT MODEL YOU WANT HERE!!! <--###\n",
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
    "model_name = 'xlnet-large-cased'\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9sC5XSh1zJnt"
   },
   "outputs": [],
   "source": [
    "def att_masking(input_ids):\n",
    "  attention_masks = []\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    attention_masks.append(att_mask)\n",
    "  return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_input_ids(all_toks):\n",
    "  splitted_toks = []\n",
    "  l=0\n",
    "  r=510\n",
    "  while(l<len(all_toks)):\n",
    "    splitted_toks.append(all_toks[l:min(r,len(all_toks))])\n",
    "    l+=410\n",
    "    r+=410\n",
    "\n",
    "  CLS = tokenizer.cls_token\n",
    "  SEP = tokenizer.sep_token\n",
    "  e_sents = []\n",
    "  for l_t in splitted_toks:\n",
    "    l_t = [CLS] + l_t + [SEP]\n",
    "    encoded_sent = tokenizer.convert_tokens_to_ids(l_t)\n",
    "    e_sents.append(encoded_sent)\n",
    "\n",
    "  e_sents = pad_sequences(e_sents, maxlen=512, value=0, dtype=\"long\", padding=\"post\")\n",
    "  att_masks = att_masking(e_sents)\n",
    "  return e_sents, att_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQbPyjPazNMC"
   },
   "outputs": [],
   "source": [
    "def generate_np_files_for_training(dataf, tokenizer):\n",
    "  all_input_ids, all_att_masks, all_labels = [], [], []\n",
    "  for i in progressbar.progressbar(range(len(dataf['text']))):\n",
    "    text = dataf['text'].iloc[i]\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    if(len(toks) > 10000):\n",
    "      toks = toks[len(toks)-10000:]\n",
    "\n",
    "    splitted_input_ids, splitted_att_masks = grouped_input_ids(toks)\n",
    "    doc_label = dataf['label'].iloc[i]\n",
    "    for i in range(len(splitted_input_ids)):\n",
    "      all_input_ids.append(splitted_input_ids[i])\n",
    "      all_att_masks.append(splitted_att_masks[i])\n",
    "      all_labels.append(doc_label)\n",
    "\n",
    "  return all_input_ids, all_att_masks, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "7145e4f4dece4c929b62807e9c46d7aa",
      "a84fc0fab6034384b029fec594c8e16b",
      "68fe1cf27d7b494f9c1cf78e5ad127ea",
      "b135242c8bee428695fe1096109fc4be",
      "709bbb69a7f943bda072abc10860a962",
      "90a56453bb264e03a793db8a1c21aaaa",
      "e0c8d6f7e2044496bc9c028433968465",
      "4d4176229eab45a0bebaa41b34f5fad6"
     ]
    },
    "colab_type": "code",
    "id": "yzkX4ggrzO8t",
    "outputId": "b755f093-c706-45b2-93bc-80c9f213eeea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased', do_lower_case=True)\n",
    "\n",
    "train_input_ids, train_att_masks, train_labels = generate_np_files_for_training(train_set, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEjcx-nMzXd7"
   },
   "outputs": [],
   "source": [
    "def input_id_maker(dataf, tokenizer):\n",
    "  input_ids = []\n",
    "  lengths = []\n",
    "\n",
    "  for i in progressbar.progressbar(range(len(dataf['text']))):\n",
    "    sen = dataf['text'].iloc[i]\n",
    "    sen = tokenizer.tokenize(sen)\n",
    "    CLS = tokenizer.cls_token\n",
    "    SEP = tokenizer.sep_token\n",
    "    if(len(sen) > 510):\n",
    "      sen = sen[len(sen)-510:]\n",
    "\n",
    "    sen = sen + [SEP] + [CLS]\n",
    "\n",
    "    encoded_sent = tokenizer.convert_tokens_to_ids(sen)\n",
    "    input_ids.append(encoded_sent)\n",
    "    lengths.append(len(encoded_sent))\n",
    "\n",
    "  input_ids = pad_sequences(input_ids, maxlen=512, value=0, dtype=\"long\", truncating=\"pre\", padding=\"pre\")\n",
    "  return input_ids, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6b7hra5izaqT",
    "outputId": "d53e07bd-4335-4744-d643-0db83152aea9"
   },
   "outputs": [],
   "source": [
    "validation_input_ids, validation_lengths = input_id_maker(validation_set, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(validation_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_len = []\n",
    "for i in progressbar.progressbar(range(len(train_set['text']))):\n",
    "    text = train_set['text'].iloc[i]\n",
    "    token_len.append(len(tokenizer.tokenize(text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ = sum(token_len)\n",
    "print(sum_)\n",
    "\n",
    "length = len(token_len)\n",
    "print(length)\n",
    "\n",
    "average = sum_/length\n",
    "\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpQRL7wEzfA2"
   },
   "outputs": [],
   "source": [
    "validation_attention_masks = att_masking(validation_input_ids)\n",
    "validation_labels = validation_set['label'].to_numpy().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-6_RPLyzg5W"
   },
   "outputs": [],
   "source": [
    "train_inputs = train_input_ids\n",
    "validation_inputs = validation_input_ids\n",
    "train_masks = train_att_masks\n",
    "validation_masks = validation_attention_masks\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVGkNTHXzi4K"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7c8e78c4e1d4423c8890bcd26f119863",
      "a886571e90f640068f42391d631b5435",
      "5e45f6a74562492681b52a469b2d7bae",
      "ed0bd4d8abc04e48be9779c9b839960c",
      "e5fa9ce813d44404951c01f934f61df0",
      "7e71194a302b420eb3c558ca6b94a42c",
      "4bccda0509c94f08bf8775292fee2492",
      "83222bc6ff79465fab144e9e93a23d19",
      "40d4070c0b6b4ccf8f64fd5966136a8d",
      "61a93549abbc48d8aa258f38251a280e",
      "efa6623cc1e44c7e999793565ca8da2b",
      "370c1110e5e64739bdead3e15a98551e",
      "b55ef8a462064d8e944ce6dc726d8df0",
      "0438ccff2f5e4f2fa001151f9daf8fbc",
      "b98b4095be9c4399a960233c9030fe8a",
      "985859d7f3a34d298a8cd3bc59f261d7"
     ]
    },
    "colab_type": "code",
    "id": "l-xcZ8mBzko_",
    "outputId": "80ba1c5c-4607-4e2b-a41d-bac61799a8bb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-large-cased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkyVneHWzmYj"
   },
   "outputs": [],
   "source": [
    "lr = 2e-6\n",
    "max_grad_norm = 1.0\n",
    "epochs = 5\n",
    "num_total_steps = len(train_dataloader)*epochs\n",
    "num_warmup_steps = 1000\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n",
    "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=True)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = num_total_steps)\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "seed_val = 21\n",
    "\n",
    "\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "train_loss_values = []\n",
    "train_accuracy = []\n",
    "val_loss_values = []\n",
    "val_accuracy = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "#             print('  Batch {:>5,}  of  {:>5,}. '.format(step, len(train_dataloader)))\n",
    "            print('  Batch {:>5,}  of  {:>5,}. : loss: {:} '.format(step, len(train_dataloader), total_loss/step))\n",
    "\n",
    "\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "          outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "    \n",
    "        logits = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BEPraZa10lO0",
    "outputId": "78cc1baf-ab74-49ba-935c-b1ec320627d5"
   },
   "outputs": [],
   "source": [
    "out_path = #output folder path name\n",
    "output_dir = out_path + #output destination folder name\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "   os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_set.label.to_numpy().astype(int)\n",
    "\n",
    "input_ids, input_lengths = input_id_maker(test_set, tokenizer)\n",
    "attention_masks = att_masking(input_ids)\n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "\n",
    "# Predict \n",
    "for (step, batch) in enumerate(prediction_dataloader):\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from google.colab import drive\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import textwrap\n",
    "import progressbar\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_calculator(preds, test_labels):\n",
    "    cm = confusion_matrix(test_labels, preds)\n",
    "    TP = []\n",
    "    FP = []\n",
    "    FN = []\n",
    "    for i in range(0,2):\n",
    "        summ = 0\n",
    "        for j in range(0,2):\n",
    "            if(i!=j):\n",
    "                summ=summ+cm[i][j]\n",
    "\n",
    "        FN.append(summ)\n",
    "    for i in range(0,2):\n",
    "        summ = 0\n",
    "        for j in range(0,2):\n",
    "            if(i!=j):\n",
    "                summ=summ+cm[j][i]\n",
    "\n",
    "        FP.append(summ)\n",
    "    for i in range(0,2):\n",
    "        TP.append(cm[i][i])\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(0,2):\n",
    "        precision.append(TP[i]/(TP[i] + FP[i]))\n",
    "        recall.append(TP[i]/(TP[i] + FN[i]))\n",
    "\n",
    "    macro_precision = sum(precision)/2\n",
    "    macro_recall = sum(recall)/2\n",
    "    micro_precision = sum(TP)/(sum(TP) + sum(FP))\n",
    "    micro_recall = sum(TP)/(sum(TP) + sum(FN))\n",
    "    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n",
    "    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision + macro_recall)\n",
    "    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size.  \n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "prediction_sampler = SequentialSampler(validation_data)\n",
    "prediction_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "\n",
    "# Predict \n",
    "for (step, batch) in enumerate(prediction_dataloader):\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "labels_flat = true_labels.flatten()\n",
    "\n",
    "flat_accuracy(predictions,true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\n",
    "print(macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\n",
    "print(\"macro_precision\", \"\\t\", \"macro_recall\", \"\\t\\t\", \"macro_f1\", \"\\t\\t\", \"accuracy\")\n",
    "print(macro_precision, \"\\t\", macro_recall, \"\\t\", macro_f1, \"\\t\", flat_accuracy(predictions,true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To save the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXi1VlA3Ogfy"
   },
   "outputs": [],
   "source": [
    "train_set = df.query(\" split=='train' \")\n",
    "test_set = df.query(\" split=='test' \")\n",
    "validation_set = df.query(\" split=='dev' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ec2lQwP4k1PW",
    "outputId": "f14d0e0a-7e7e-44ba-c8a3-860adb235d78"
   },
   "outputs": [],
   "source": [
    "out_path = #output folder path name\n",
    "output_dir = out_path + #output destination folder name\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-large-cased\", output_hidden_states=True)\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTAVFo6lQpg5"
   },
   "outputs": [],
   "source": [
    "def att_masking(input_ids):\n",
    "  attention_masks = []\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    attention_masks.append(att_mask)\n",
    "  return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_input_ids(all_toks):\n",
    "  splitted_toks = []\n",
    "  l=0\n",
    "  r=510\n",
    "  while(l<len(all_toks)):\n",
    "    splitted_toks.append(all_toks[l:min(r,len(all_toks))])\n",
    "    l+=410\n",
    "    r+=410\n",
    "\n",
    "  CLS = tokenizer.cls_token\n",
    "  SEP = tokenizer.sep_token\n",
    "  e_sents = []\n",
    "  for l_t in splitted_toks:\n",
    "    l_t = [CLS] + l_t + [SEP]\n",
    "        \n",
    "#     l_t = l_t + [SEP] + [CLS]\n",
    "    encoded_sent = tokenizer.convert_tokens_to_ids(l_t)\n",
    "    e_sents.append(encoded_sent)\n",
    "\n",
    "  e_sents = pad_sequences(e_sents, maxlen=512, value=0, dtype=\"long\", padding=\"pre\")\n",
    "  att_masks = att_masking(e_sents)\n",
    "  return e_sents, att_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNyZuxeJRoT1"
   },
   "outputs": [],
   "source": [
    "def get_output_for_one_vec(input_id, att_mask):\n",
    "  input_ids = torch.tensor(input_id)\n",
    "  att_masks = torch.tensor(att_mask)\n",
    "  input_ids = input_ids.unsqueeze(0)\n",
    "  att_masks = att_masks.unsqueeze(0)\n",
    "  model.eval()\n",
    "  input_ids = input_ids.to(device)\n",
    "  att_masks = att_masks.to(device)\n",
    "  with torch.no_grad():\n",
    "      encoded_layers = model(input_ids=input_ids, token_type_ids=None, attention_mask=att_masks).hidden_states\n",
    "  \n",
    "  vec = encoded_layers[24][0][-1]\n",
    "#   print(len(vec), vec)\n",
    "  vec = vec.detach().cpu().numpy()\n",
    "  return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3Vx-uCCkcc4"
   },
   "outputs": [],
   "source": [
    "def generate_np_files_for_emb(dataf, tokenizer):\n",
    "  all_docs = []\n",
    "  for i in progressbar.progressbar(range(len(dataf['text']))):\n",
    "    text = dataf['text'].iloc[i]\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    if(len(toks) > 10000):\n",
    "      toks = toks[len(toks)-10000:]\n",
    "\n",
    "    splitted_input_ids, splitted_att_masks = grouped_input_ids(toks)\n",
    "\n",
    "    vecs = []\n",
    "    for index,ii in enumerate(splitted_input_ids):\n",
    "      vecs.append(get_output_for_one_vec(ii, splitted_att_masks[index]))\n",
    " \n",
    "    one_doc = np.asarray(vecs)\n",
    "    all_docs.append(one_doc)\n",
    "\n",
    "  all_docs = np.asarray(all_docs)\n",
    "  return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_numpy = #folder path\n",
    "dire_name = #destination folder name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_numpy + dire_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if needed\n",
    "if not os.path.exists(path_to_save_numpy + dire_name):\n",
    "   os.makedirs(path_to_save_numpy + dire_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1Ju0fEgAkenP",
    "outputId": "fd68b4d0-42d5-4b48-8b09-8d2d8189c9e4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vecs_dev = generate_np_files_for_emb(validation_set, tokenizer)\n",
    "np.save(path_to_save_numpy + dire_name + \"XLNetLarge_dev.npy\", vecs_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_train = generate_np_files_for_emb(train_set, tokenizer)\n",
    "np.save(path_to_save_numpy + dire_name + \"XLNetLarge_train.npy\", vecs_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "XLNet_mini.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0438ccff2f5e4f2fa001151f9daf8fbc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "370c1110e5e64739bdead3e15a98551e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_985859d7f3a34d298a8cd3bc59f261d7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b98b4095be9c4399a960233c9030fe8a",
      "value": " 467M/467M [00:29&lt;00:00, 15.7MB/s]"
     }
    },
    "40d4070c0b6b4ccf8f64fd5966136a8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_efa6623cc1e44c7e999793565ca8da2b",
       "IPY_MODEL_370c1110e5e64739bdead3e15a98551e"
      ],
      "layout": "IPY_MODEL_61a93549abbc48d8aa258f38251a280e"
     }
    },
    "4bccda0509c94f08bf8775292fee2492": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d4176229eab45a0bebaa41b34f5fad6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e45f6a74562492681b52a469b2d7bae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e71194a302b420eb3c558ca6b94a42c",
      "max": 760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5fa9ce813d44404951c01f934f61df0",
      "value": 760
     }
    },
    "61a93549abbc48d8aa258f38251a280e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68fe1cf27d7b494f9c1cf78e5ad127ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90a56453bb264e03a793db8a1c21aaaa",
      "max": 798011,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_709bbb69a7f943bda072abc10860a962",
      "value": 798011
     }
    },
    "709bbb69a7f943bda072abc10860a962": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7145e4f4dece4c929b62807e9c46d7aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_68fe1cf27d7b494f9c1cf78e5ad127ea",
       "IPY_MODEL_b135242c8bee428695fe1096109fc4be"
      ],
      "layout": "IPY_MODEL_a84fc0fab6034384b029fec594c8e16b"
     }
    },
    "7c8e78c4e1d4423c8890bcd26f119863": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e45f6a74562492681b52a469b2d7bae",
       "IPY_MODEL_ed0bd4d8abc04e48be9779c9b839960c"
      ],
      "layout": "IPY_MODEL_a886571e90f640068f42391d631b5435"
     }
    },
    "7e71194a302b420eb3c558ca6b94a42c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83222bc6ff79465fab144e9e93a23d19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90a56453bb264e03a793db8a1c21aaaa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "985859d7f3a34d298a8cd3bc59f261d7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a84fc0fab6034384b029fec594c8e16b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a886571e90f640068f42391d631b5435": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b135242c8bee428695fe1096109fc4be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d4176229eab45a0bebaa41b34f5fad6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e0c8d6f7e2044496bc9c028433968465",
      "value": " 798k/798k [00:00&lt;00:00, 5.26MB/s]"
     }
    },
    "b55ef8a462064d8e944ce6dc726d8df0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b98b4095be9c4399a960233c9030fe8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0c8d6f7e2044496bc9c028433968465": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5fa9ce813d44404951c01f934f61df0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ed0bd4d8abc04e48be9779c9b839960c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83222bc6ff79465fab144e9e93a23d19",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4bccda0509c94f08bf8775292fee2492",
      "value": " 760/760 [01:07&lt;00:00, 11.2B/s]"
     }
    },
    "efa6623cc1e44c7e999793565ca8da2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0438ccff2f5e4f2fa001151f9daf8fbc",
      "max": 467042463,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b55ef8a462064d8e944ce6dc726d8df0",
      "value": 467042463
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
